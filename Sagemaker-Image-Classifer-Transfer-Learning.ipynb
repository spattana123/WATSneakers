{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Deploying a Custom Image Classifier with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure where to fetch our training data\n",
    "\n",
    "All of our images live inside an S3 bucket, organized into folders in a structure similar to this:\n",
    "\n",
    "```\n",
    "my_training_classes\n",
    "├── person\n",
    "│   ├── han.jpg\n",
    "│   ├── leia.jpg\n",
    "|   ├── luke.jpg\n",
    "│   └── . . .\n",
    "└── ship\n",
    "│   ├── millenium_falcon.jpg\n",
    "│   ├── tie-fighter.jpg    \n",
    "│   ├── x-wing.jpg\n",
    "│   ├── . . .\n",
    "└── . . .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seanbrown/projects/WATSneakers'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that should work :-)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "logger.info('that should work :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data bucket name is: sagemakertestwat\n",
      "dataset name is: INC_DATA\n"
     ]
    }
   ],
   "source": [
    "# An S3 Bucket Name\n",
    "data_bucket_name='sagemakertestwat'\n",
    "\n",
    "# A prefix name inside the S3 bucket containing sub-folders of images (one per label class)\n",
    "dataset_name = 'INC_DATA' \n",
    "\n",
    "logger.info(\"data bucket name is: \"+data_bucket_name);\n",
    "logger.info(\"dataset name is: \"+dataset_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "Here we set up the linkage and authentication to AWS services\n",
    "\n",
    "- The role used to give learning and hosting access to your data. This will automatically be obtained from the role used to start the notebook\n",
    "- A `session` variable that holds some configuration state for interacting with SageMaker from Python and contains some methods for preparing input data\n",
    "- A reference to the Amazon sagemaker image classification docker image \n",
    "\n",
    "More info about the SageMaker built-in Image Classification algorithm here: https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane\n",
      "Changing event name from before-call.apigateway to before-call.api-gateway\n",
      "Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict\n",
      "Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration\n",
      "Changing event name from before-parameter-build.route53 to before-parameter-build.route-53\n",
      "Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search\n",
      "Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section\n",
      "Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask\n",
      "Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section\n",
      "Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search\n",
      "Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/boto3/data/s3/2006-03-01/resources-1.json\n",
      "IMDS ENDPOINT: http://169.254.169.254/\n",
      "Looking for credentials via: env\n",
      "Looking for credentials via: assume-role\n",
      "Looking for credentials via: assume-role-with-web-identity\n",
      "Looking for credentials via: sso\n",
      "Looking for credentials via: shared-credentials-file\n",
      "Found credentials in shared credentials file: ~/.aws/credentials\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/endpoints.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sdk-default-configuration.json\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/s3/2006-03-01/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/s3/2006-03-01/endpoint-rule-set-1.json.gz\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/partitions.json\n",
      "Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8c27c61750>\n",
      "Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8c272afe20>\n",
      "Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Setting s3 timeout as (60, 60)\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/_retry.json\n",
      "Registering retry handlers for service: s3\n",
      "Registering S3 region redirector handler\n",
      "Loading s3:s3\n",
      "Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane\n",
      "Changing event name from before-call.apigateway to before-call.api-gateway\n",
      "Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict\n",
      "Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration\n",
      "Changing event name from before-parameter-build.route53 to before-parameter-build.route-53\n",
      "Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search\n",
      "Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section\n",
      "Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask\n",
      "Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section\n",
      "Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search\n",
      "Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker/2017-07-24/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/emr/2009-03-31/service-2.json\n",
      "Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane\n",
      "Changing event name from before-call.apigateway to before-call.api-gateway\n",
      "Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict\n",
      "Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration\n",
      "Changing event name from before-parameter-build.route53 to before-parameter-build.route-53\n",
      "Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search\n",
      "Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section\n",
      "Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask\n",
      "Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section\n",
      "Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search\n",
      "Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section\n",
      "IMDS ENDPOINT: http://169.254.169.254/\n",
      "Looking for credentials via: env\n",
      "Looking for credentials via: assume-role\n",
      "Looking for credentials via: assume-role-with-web-identity\n",
      "Looking for credentials via: sso\n",
      "Looking for credentials via: shared-credentials-file\n",
      "Found credentials in shared credentials file: ~/.aws/credentials\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/endpoints.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sdk-default-configuration.json\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker/2017-07-24/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker/2017-07-24/endpoint-rule-set-1.json.gz\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/partitions.json\n",
      "Event creating-client-class.sagemaker: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Setting api.sagemaker timeout as (60, 60)\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/_retry.json\n",
      "Registering retry handlers for service: sagemaker\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker-runtime/2017-05-13/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker-runtime/2017-05-13/endpoint-rule-set-1.json.gz\n",
      "Event creating-client-class.sagemaker-runtime: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Setting runtime.sagemaker timeout as (60, 80)\n",
      "Registering retry handlers for service: sagemaker-runtime\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker-featurestore-runtime/2020-07-01/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker-featurestore-runtime/2020-07-01/endpoint-rule-set-1.json.gz\n",
      "Event creating-client-class.sagemaker-featurestore-runtime: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a regex based endpoint for featurestore-runtime.sagemaker, us-east-1\n",
      "Setting featurestore-runtime.sagemaker timeout as (60, 60)\n",
      "Registering retry handlers for service: sagemaker-featurestore-runtime\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker-metrics/2022-09-30/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sagemaker-metrics/2022-09-30/endpoint-rule-set-1.json.gz\n",
      "Event creating-client-class.sagemaker-metrics: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Setting metrics.sagemaker timeout as (60, 60)\n",
      "Registering retry handlers for service: sagemaker-metrics\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/boto3/data/s3/2006-03-01/resources-1.json\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/s3/2006-03-01/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/s3/2006-03-01/endpoint-rule-set-1.json.gz\n",
      "Event creating-client-class.s3: calling handler <function add_generate_presigned_post at 0x7f8c27c61750>\n",
      "Event creating-client-class.s3: calling handler <function lazy_call.<locals>._handler at 0x7f8c2b24d120>\n",
      "Event creating-client-class.s3: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Setting s3 timeout as (60, 60)\n",
      "Registering retry handlers for service: s3\n",
      "Registering S3 region redirector handler\n",
      "Loading s3:s3\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/endpoints.json\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sts/2011-06-15/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/sts/2011-06-15/endpoint-rule-set-1.json.gz\n",
      "Event creating-client-class.sts: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Setting sts timeout as (60, 60)\n",
      "Registering retry handlers for service: sts\n",
      "Calling endpoint provider with parameters: {'Region': 'us-east-1', 'UseDualStack': False, 'UseFIPS': False, 'Endpoint': 'https://sts.us-east-1.amazonaws.com', 'UseGlobalEndpoint': True}\n",
      "Endpoint provider result: https://sts.us-east-1.amazonaws.com\n",
      "Event before-parameter-build.sts.GetCallerIdentity: calling handler <function generate_idempotent_uuid at 0x7f8c27cdb400>\n",
      "Event before-call.sts.GetCallerIdentity: calling handler <function add_recursion_detection_header at 0x7f8c27cdb0a0>\n",
      "Event before-call.sts.GetCallerIdentity: calling handler <function inject_api_version_header_if_needed at 0x7f8c27e00ca0>\n",
      "Making request for OperationModel(name=GetCallerIdentity) with params: {'url_path': '/', 'query_string': '', 'method': 'POST', 'headers': {'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8', 'User-Agent': 'Boto3/1.26.90 Python/3.10.8 Darwin/22.3.0 Botocore/1.29.90'}, 'body': {'Action': 'GetCallerIdentity', 'Version': '2011-06-15'}, 'url': 'https://sts.us-east-1.amazonaws.com/', 'context': {'client_region': 'us-east-1', 'client_config': <botocore.config.Config object at 0x7f8c2c543a90>, 'has_streaming_input': False, 'auth_type': None}}\n",
      "Event request-created.sts.GetCallerIdentity: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7f8c2c543b80>>\n",
      "Event choose-signer.sts.GetCallerIdentity: calling handler <function set_operation_specific_signer at 0x7f8c27cdb2e0>\n",
      "Calculating signature using v4 auth.\n",
      "CanonicalRequest:\n",
      "POST\n",
      "/\n",
      "\n",
      "content-type:application/x-www-form-urlencoded; charset=utf-8\n",
      "host:sts.us-east-1.amazonaws.com\n",
      "x-amz-date:20230407T001741Z\n",
      "\n",
      "content-type;host;x-amz-date\n",
      "ab821ae955788b0e33ebd34c208442ccfc2d406e2edc5e7a39bd6458fbb4f843\n",
      "StringToSign:\n",
      "AWS4-HMAC-SHA256\n",
      "20230407T001741Z\n",
      "20230407/us-east-1/sts/aws4_request\n",
      "423963810faea7636cb4fe699540c91ecfde99f8f5e0778e6d78a9e7e63cca68\n",
      "Signature:\n",
      "36bb78253f591ab8a5e8e5b9a714debde7b3295ea50cd3aee751a7c7d07113e3\n",
      "Event request-created.sts.GetCallerIdentity: calling handler <function add_retry_headers at 0x7f8c27e01360>\n",
      "Sending http request: <AWSPreparedRequest stream_output=False, method=POST, url=https://sts.us-east-1.amazonaws.com/, headers={'Content-Type': b'application/x-www-form-urlencoded; charset=utf-8', 'User-Agent': b'Boto3/1.26.90 Python/3.10.8 Darwin/22.3.0 Botocore/1.29.90', 'X-Amz-Date': b'20230407T001741Z', 'Authorization': b'AWS4-HMAC-SHA256 Credential=AKIA33EHRS26U4KVLXVO/20230407/us-east-1/sts/aws4_request, SignedHeaders=content-type;host;x-amz-date, Signature=36bb78253f591ab8a5e8e5b9a714debde7b3295ea50cd3aee751a7c7d07113e3', 'amz-sdk-invocation-id': b'd705e801-858e-4257-a912-52d8389ff83f', 'amz-sdk-request': b'attempt=1', 'Content-Length': '43'}>\n",
      "Certificate path: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/certifi/cacert.pem\n",
      "Starting new HTTPS connection (1): sts.us-east-1.amazonaws.com:443\n",
      "https://sts.us-east-1.amazonaws.com:443 \"POST / HTTP/1.1\" 200 407\n",
      "Response headers: {'x-amzn-RequestId': '7d7357ef-5198-4745-bf70-8a95c86d0d94', 'Content-Type': 'text/xml', 'Content-Length': '407', 'Date': 'Fri, 07 Apr 2023 00:17:41 GMT'}\n",
      "Response body:\n",
      "b'<GetCallerIdentityResponse xmlns=\"https://sts.amazonaws.com/doc/2011-06-15/\">\\n  <GetCallerIdentityResult>\\n    <Arn>arn:aws:iam::814180570813:user/sean.brown</Arn>\\n    <UserId>AIDA33EHRS26T6AARYHKD</UserId>\\n    <Account>814180570813</Account>\\n  </GetCallerIdentityResult>\\n  <ResponseMetadata>\\n    <RequestId>7d7357ef-5198-4745-bf70-8a95c86d0d94</RequestId>\\n  </ResponseMetadata>\\n</GetCallerIdentityResponse>\\n'\n",
      "Event needs-retry.sts.GetCallerIdentity: calling handler <botocore.retryhandler.RetryHandler object at 0x7f8c2c541bd0>\n",
      "No retry needed.\n",
      "Event choose-service-name: calling handler <function handle_service_name_alias at 0x7f8c27cd9e10>\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/iam/2010-05-08/service-2.json\n",
      "Loading JSON file: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/botocore/data/iam/2010-05-08/endpoint-rule-set-1.json.gz\n",
      "Event creating-client-class.iam: calling handler <function add_generate_presigned_url at 0x7f8c27c61510>\n",
      "Using partition endpoint for iam, us-east-1: aws-global\n",
      "Setting iam timeout as (60, 60)\n",
      "Registering retry handlers for service: iam\n",
      "Calling endpoint provider with parameters: {'Region': 'us-east-1', 'UseDualStack': False, 'UseFIPS': False}\n",
      "Endpoint provider result: https://iam.amazonaws.com\n",
      "Selecting from endpoint provider's list of auth schemes: \"sigv4\". User selected auth scheme is: \"None\"\n",
      "Selected auth type \"v4\" as \"v4\" with signing context params: {'region': 'us-east-1', 'signing_name': 'iam'}\n",
      "Event before-parameter-build.iam.GetRole: calling handler <function generate_idempotent_uuid at 0x7f8c27cdb400>\n",
      "Event before-call.iam.GetRole: calling handler <function add_recursion_detection_header at 0x7f8c27cdb0a0>\n",
      "Event before-call.iam.GetRole: calling handler <function inject_api_version_header_if_needed at 0x7f8c27e00ca0>\n",
      "Making request for OperationModel(name=GetRole) with params: {'url_path': '/', 'query_string': '', 'method': 'POST', 'headers': {'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8', 'User-Agent': 'Boto3/1.26.90 Python/3.10.8 Darwin/22.3.0 Botocore/1.29.90'}, 'body': {'Action': 'GetRole', 'Version': '2010-05-08', 'RoleName': 'sean.brown'}, 'url': 'https://iam.amazonaws.com/', 'context': {'client_region': 'aws-global', 'client_config': <botocore.config.Config object at 0x7f8c2c829cf0>, 'has_streaming_input': False, 'auth_type': 'v4', 'signing': {'region': 'us-east-1', 'signing_name': 'iam'}}}\n",
      "Event request-created.iam.GetRole: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7f8c2c543d60>>\n",
      "Event choose-signer.iam.GetRole: calling handler <function set_operation_specific_signer at 0x7f8c27cdb2e0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating signature using v4 auth.\n",
      "CanonicalRequest:\n",
      "POST\n",
      "/\n",
      "\n",
      "content-type:application/x-www-form-urlencoded; charset=utf-8\n",
      "host:iam.amazonaws.com\n",
      "x-amz-date:20230407T001741Z\n",
      "\n",
      "content-type;host;x-amz-date\n",
      "76f278de53ce1c578848a40b3c1644dadeb785f6aabad2445fe51d539bcd81c0\n",
      "StringToSign:\n",
      "AWS4-HMAC-SHA256\n",
      "20230407T001741Z\n",
      "20230407/us-east-1/iam/aws4_request\n",
      "725fe9d70d3d0f32e2eceece296b5f96a00e92dc8b64b0114d30fbd7a4543b33\n",
      "Signature:\n",
      "1474bcfd13168a4573075673002f5c4436f371410aab651b1375b5e3c78a21d2\n",
      "Event request-created.iam.GetRole: calling handler <function add_retry_headers at 0x7f8c27e01360>\n",
      "Sending http request: <AWSPreparedRequest stream_output=False, method=POST, url=https://iam.amazonaws.com/, headers={'Content-Type': b'application/x-www-form-urlencoded; charset=utf-8', 'User-Agent': b'Boto3/1.26.90 Python/3.10.8 Darwin/22.3.0 Botocore/1.29.90', 'X-Amz-Date': b'20230407T001741Z', 'Authorization': b'AWS4-HMAC-SHA256 Credential=AKIA33EHRS26U4KVLXVO/20230407/us-east-1/iam/aws4_request, SignedHeaders=content-type;host;x-amz-date, Signature=1474bcfd13168a4573075673002f5c4436f371410aab651b1375b5e3c78a21d2', 'amz-sdk-invocation-id': b'7fae9d43-a0ed-45d9-9a1c-4dfc44ed95d7', 'amz-sdk-request': b'attempt=1', 'Content-Length': '53'}>\n",
      "Certificate path: /Users/seanbrown/miniconda3/lib/python3.10/site-packages/certifi/cacert.pem\n",
      "Starting new HTTPS connection (1): iam.amazonaws.com:443\n",
      "https://iam.amazonaws.com:443 \"POST / HTTP/1.1\" 404 290\n",
      "Response headers: {'x-amzn-RequestId': 'ed8f9cef-2cb0-4f37-994d-3f912253da8a', 'Content-Type': 'text/xml', 'Content-Length': '290', 'Date': 'Fri, 07 Apr 2023 00:17:41 GMT'}\n",
      "Response body:\n",
      "b'<ErrorResponse xmlns=\"https://iam.amazonaws.com/doc/2010-05-08/\">\\n  <Error>\\n    <Type>Sender</Type>\\n    <Code>NoSuchEntity</Code>\\n    <Message>The role with name sean.brown cannot be found.</Message>\\n  </Error>\\n  <RequestId>ed8f9cef-2cb0-4f37-994d-3f912253da8a</RequestId>\\n</ErrorResponse>\\n'\n",
      "Response headers: {'x-amzn-RequestId': 'ed8f9cef-2cb0-4f37-994d-3f912253da8a', 'Content-Type': 'text/xml', 'Content-Length': '290', 'Date': 'Fri, 07 Apr 2023 00:17:41 GMT'}\n",
      "Response body:\n",
      "b'<ErrorResponse xmlns=\"https://iam.amazonaws.com/doc/2010-05-08/\">\\n  <Error>\\n    <Type>Sender</Type>\\n    <Code>NoSuchEntity</Code>\\n    <Message>The role with name sean.brown cannot be found.</Message>\\n  </Error>\\n  <RequestId>ed8f9cef-2cb0-4f37-994d-3f912253da8a</RequestId>\\n</ErrorResponse>\\n'\n",
      "Event needs-retry.iam.GetRole: calling handler <botocore.retryhandler.RetryHandler object at 0x7f8c2c8b08e0>\n",
      "No retry needed.\n",
      "Event after-call.iam.GetRole: calling handler <function json_decode_policies at 0x7f8c27cdbf40>\n",
      "Couldn't call 'get_role' to get Role ARN from role name sean.brown to get Role path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The current AWS identity is not a role: arn:aws:iam::814180570813:user/sean.brown, therefore it cannot be used as a SageMaker execution role",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_execution_role\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamazon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamazon_estimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_image_uri\n\u001b[0;32m----> 5\u001b[0m role \u001b[38;5;241m=\u001b[39m \u001b[43mget_execution_role\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m sess \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m      8\u001b[0m training_image \u001b[38;5;241m=\u001b[39m get_image_uri(sess\u001b[38;5;241m.\u001b[39mboto_region_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage-classification\u001b[39m\u001b[38;5;124m'\u001b[39m, repo_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sagemaker/session.py:5900\u001b[0m, in \u001b[0;36mget_execution_role\u001b[0;34m(sagemaker_session)\u001b[0m\n\u001b[1;32m   5895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arn\n\u001b[1;32m   5896\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current AWS identity is not a role: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, therefore it cannot be used as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSageMaker execution role\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5899\u001b[0m )\n\u001b[0;32m-> 5900\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message\u001b[38;5;241m.\u001b[39mformat(arn))\n",
      "\u001b[0;31mValueError\u001b[0m: The current AWS identity is not a role: arn:aws:iam::814180570813:user/sean.brown, therefore it cannot be used as a SageMaker execution role"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "\n",
    "logger.info(training_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for our model\n",
    "Before we can train our model, we need to:\n",
    "\n",
    "- Create some files that will teach SageMaker about the images in each of our classes\n",
    "- Upload these additional files to S3\n",
    "- Configure our model to use these files for training and validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the im2rec.py script on this system\n",
    "The SageMaker image classifier algorithm needs to know about which images belong to which classes. We provide this data using either LST or RecordIO files. We'll use a python script called `im2rec.py` to create these files.\n",
    "\n",
    "More info here: https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html#IC-inputoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERM_PROGRAM=vscode\n",
      "SQLUSERNAME=MetaDataAdmin\n",
      "TERM=xterm-color\n",
      "SHELL=/bin/zsh\n",
      "CLICOLOR=1\n",
      "SQLURL=shoe-meta-data.cb6nyk6ym2ie.us-west-1.rds.amazonaws.com\n",
      "TMPDIR=/var/folders/3y/yngy_smj2t7dn9dkmtbx07d00000gn/T/\n",
      "CONDA_SHLVL=1\n",
      "TERM_PROGRAM_VERSION=1.76.2\n",
      "CONDA_PROMPT_MODIFIER=(base) \n",
      "BUCKET=sagemakertestwat\n",
      "ZDOTDIR=/Users/seanbrown\n",
      "ORIGINAL_XDG_CURRENT_DESKTOP=undefined\n",
      "MallocNanoZone=0\n",
      "ZSH=/Users/seanbrown/.oh-my-zsh\n",
      "SQLPASSWORD=smTKM2TGAaRGdzDQ6gQJ\n",
      "USER=seanbrown\n",
      "DATASET_NAME=INC_DATA\n",
      "LS_COLORS=di=1;36:ln=35:so=32:pi=33:ex=31:bd=34;46:cd=34;43:su=30;41:sg=30;46:tw=30;42:ow=30;43\n",
      "COMMAND_MODE=unix2003\n",
      "CONDA_EXE=/Users/seanbrown/miniconda3/bin/conda\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.eQ4iG7Kc9V/Listeners\n",
      "__CF_USER_TEXT_ENCODING=0x1F5:0x0:0x0\n",
      "JPY_PARENT_PID=37294\n",
      "PAGER=cat\n",
      "_CE_CONDA=\n",
      "LSCOLORS=Gxfxcxdxbxegedabagacad\n",
      "S3_DATA_BUCKET_NAME=sagemakertestwat\n",
      "PATH=/Users/seanbrown/.amplify/bin:/usr/local/opt/ruby/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion.app/Contents/Public:/usr/local/MacGPG2/bin:/usr/local/share/dotnet:/opt/X11/bin:~/.dotnet/tools:/Library/Apple/usr/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Applications/Wireshark.app/Contents/MacOS:/Users/seanbrown/.amplify/bin:/usr/local/opt/ruby/bin:/Users/seanbrown/miniconda3/bin:/Users/seanbrown/miniconda3/condabin:/Users/seanbrown/projects/flutter-development-repo/flutter/bin:/Users/seanbrown/projects/flutter-development-repo/flutter/bin\n",
      "_=/usr/bin/env\n",
      "USER_ZDOTDIR=/Users/seanbrown\n",
      "CONDA_PREFIX=/Users/seanbrown/miniconda3\n",
      "__CFBundleIdentifier=com.microsoft.VSCode\n",
      "PWD=/Users/seanbrown/projects/WATSneakers\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "LANG=en_US.UTF-8\n",
      "BASE_DIR=/tmp\n",
      "VSCODE_GIT_ASKPASS_EXTRA_ARGS=--ms-enable-electron-run-as-node\n",
      "XPC_FLAGS=0x0\n",
      "FORCE_COLOR=1\n",
      "_CE_M=\n",
      "ENDPOINT=image-classification-2022-12-30-07-15-19-526\n",
      "XPC_SERVICE_NAME=0\n",
      "VSCODE_INJECTION=1\n",
      "SHLVL=4\n",
      "HOME=/Users/seanbrown\n",
      "VSCODE_GIT_ASKPASS_MAIN=/Applications/Visual Studio Code.app/Contents/Resources/app/extensions/git/dist/askpass-main.js\n",
      "LESS=-R\n",
      "CONDA_PYTHON_EXE=/Users/seanbrown/miniconda3/bin/python\n",
      "LOGNAME=seanbrown\n",
      "PREFIX=data3/\n",
      "VSCODE_GIT_IPC_HANDLE=/var/folders/3y/yngy_smj2t7dn9dkmtbx07d00000gn/T/vscode-git-0464ca11ac.sock\n",
      "CLICOLOR_FORCE=1\n",
      "CONDA_DEFAULT_ENV=base\n",
      "VSCODE_GIT_ASKPASS_NODE=/Applications/Visual Studio Code.app/Contents/Frameworks/Code Helper (Plugin).app/Contents/MacOS/Code Helper (Plugin)\n",
      "GIT_ASKPASS=/Applications/Visual Studio Code.app/Contents/Resources/app/extensions/git/dist/askpass.sh\n",
      "DISPLAY=/private/tmp/com.apple.launchd.MBYR4f6mnc/org.macosforge.xquartz:0\n",
      "GIT_PAGER=cat\n",
      "COLORTERM=truecolor\n",
      "SQLDBNAME=shoe_data\n",
      "SUFFIX=/mxnet/tools/im2rec.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "env: setenv =/mxnet/tools/: Invalid argument\n",
      "usage: mkdir [-pv] [-m mode] directory_name ...\n",
      "mount: /mxnet: invalid special file or file system.\n",
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m'\u001b[m\u001b[m\n",
      "Sagemaker-Image-Classifer-Transfer-Learning.ipynb\n",
      "\u001b[1m\u001b[36menv\u001b[m\u001b[m\n",
      "im2rec.py\n",
      "life_cycle_configuration_image_classifier.sh\n",
      "requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "env SUFFIX='/mxnet/tools/im2rec.py'\n",
    "env $DIR='/mxnet/tools/'\n",
    "mkdir -p $DIR\n",
    "mount -o remount,rw /mxnet\n",
    "wget -P $DIR https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py\n",
    "ls $DIR\n",
    "SUFFIX=$SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE_DIR=/tmp\n",
      "env: S3_DATA_BUCKET_NAME=sagemakertestwat\n",
      "env: DATASET_NAME=INC_DATA\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATASET_NAME = $dataset_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# get im2rec SWITCH THESE TO BASH COPMMANDS\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m im2rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# # Run the command and capture the output\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# output = subprocess.check_output(\"pwd\", shell=True)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # Decode the output bytes to a string\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# output_str = output.decode(\"utf-8\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mim2rec is: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mim2rec)\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATASET_NAME = $dataset_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# get im2rec SWITCH THESE TO BASH COPMMANDS\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m im2rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m((\u001b[38;5;28;01mlambda\u001b[39;00m x: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m )), sys\u001b[38;5;241m.\u001b[39mpath))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# # Run the command and capture the output\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# output = subprocess.check_output(\"pwd\", shell=True)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # Decode the output bytes to a string\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# output_str = output.decode(\"utf-8\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mim2rec is: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mim2rec)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "# Find im2rec in our environment and set up some other vars in our environemnt\n",
    "import os\n",
    "base_dir='/tmp'\n",
    "suffix = os.getenv(\"SUFFIX\")\n",
    "%env BASE_DIR=$base_dir\n",
    "%env S3_DATA_BUCKET_NAME = $data_bucket_name\n",
    "%env DATASET_NAME = $dataset_name\n",
    "# get im2rec SWITCH THESE TO BASH COPMMANDS\n",
    "im2rec = list(filter((lambda x: os.path.isfile(x + suffix )), sys.path))[0] + suffix\n",
    "# # Run the command and capture the output\n",
    "# output = subprocess.check_output(\"pwd\", shell=True)\n",
    "\n",
    "# # Decode the output bytes to a string\n",
    "# output_str = output.decode(\"utf-8\")\n",
    "logger.info(\"im2rec is: \"+im2rec)\n",
    "%env IM2REC=$im2rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our training images from S3\n",
    "In order to create training and validation RecordIO files, we need to download our images to our local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull our images from S3\n",
    "!aws s3 sync s3://$S3_DATA_BUCKET_NAME/$DATASET_NAME $BASE_DIR/$DATASET_NAME --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RecordIO files from our training images\n",
    "The `im2rec.py` script can create LST files and/or RecordIO files from our training data. \n",
    "\n",
    "More info here: https://mxnet.incubator.apache.org/versions/master/faq/recordio.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LST files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/python@2/bin/python2.7: can't find '__main__' module in '/Users/seanbrown/projects/WATSneakers'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes:\n",
      "Creating RecordIO files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/python@2/bin/python2.7: can't find '__main__' module in '/Users/seanbrown/projects/WATSneakers'\n",
      "/usr/local/opt/python@2/bin/python2.7: can't find '__main__' module in '/Users/seanbrown/projects/WATSneakers'\n",
      "ls: *.rec: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'# Use the IM2REC script to convert our images into RecordIO files\\n\\n# Clean up our working dir of existing LST and REC files\\ncd $BASE_DIR\\n#rm *.rec\\n#rm *.lst\\n\\n# First we need to create two LST files (training and test lists), noting the correct label class for each image\\n# We\\'ll also save the output of the LST files command, since it includes a list of all of our label classes\\necho \"Creating LST files\"\\npython $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\\n\\necho \"Label classes:\"\\ncat ${DATASET_NAME}_classes\\n\\n# Then we create RecordIO files from the LST files\\necho \"Creating RecordIO files\"\\npython $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\\npython $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\\nls -lh *.rec\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m# Use the IM2REC script to convert our images into RecordIO files\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Clean up our working dir of existing LST and REC files\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcd $BASE_DIR\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#rm *.rec\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#rm *.lst\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# First we need to create two LST files (training and test lists), noting the correct label class for each image\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# We\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mll also save the output of the LST files command, since it includes a list of all of our label classes\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mecho \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCreating LST files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > $\u001b[39;49m\u001b[38;5;132;43;01m{DATASET_NAME}\u001b[39;49;00m\u001b[38;5;124;43m_classes\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mecho \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabel classes:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcat $\u001b[39;49m\u001b[38;5;132;43;01m{DATASET_NAME}\u001b[39;49;00m\u001b[38;5;124;43m_classes\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Then we create RecordIO files from the LST files\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mecho \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCreating RecordIO files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython $IM2REC --num-thread=4 $\u001b[39;49m\u001b[38;5;132;43;01m{DATASET_NAME}\u001b[39;49;00m\u001b[38;5;124;43m_train.lst $DATASET_NAME\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython $IM2REC --num-thread=4 $\u001b[39;49m\u001b[38;5;132;43;01m{DATASET_NAME}\u001b[39;49;00m\u001b[38;5;124;43m_test.lst $DATASET_NAME\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mls -lh *.rec\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2422\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2421\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2422\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'# Use the IM2REC script to convert our images into RecordIO files\\n\\n# Clean up our working dir of existing LST and REC files\\ncd $BASE_DIR\\n#rm *.rec\\n#rm *.lst\\n\\n# First we need to create two LST files (training and test lists), noting the correct label class for each image\\n# We\\'ll also save the output of the LST files command, since it includes a list of all of our label classes\\necho \"Creating LST files\"\\npython $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\\n\\necho \"Label classes:\"\\ncat ${DATASET_NAME}_classes\\n\\n# Then we create RecordIO files from the LST files\\necho \"Creating RecordIO files\"\\npython $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\\npython $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\\nls -lh *.rec\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use the IM2REC script to convert our images into RecordIO files\n",
    "\n",
    "# Clean up our working dir of existing LST and REC files\n",
    "cd $BASE_DIR\n",
    "#rm *.rec\n",
    "#rm *.lst\n",
    "\n",
    "# First we need to create two LST files (training and test lists), noting the correct label class for each image\n",
    "# We'll also save the output of the LST files command, since it includes a list of all of our label classes\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat ${DATASET_NAME}_classes\n",
    "\n",
    "# Then we create RecordIO files from the LST files\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload our training and test data RecordIO files so we can train with them\n",
    "Now that we have our training and test .rec files, we upload them to S3 so SageMaker can use them for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload our train and test RecordIO files to S3 in the bucket that our sagemaker session is using\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3train_path = 's3://{}/{}/train/'.format(bucket, dataset_name)\n",
    "s3validation_path = 's3://{}/{}/validation/'.format(bucket, dataset_name)\n",
    "\n",
    "logger.info(\"s3 file training path is: \"+s3train_path)\n",
    "logger.info(\"s3 file validation path is: \"+s3validation_path)\n",
    "\n",
    "# Clean up any existing data\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/train --recursive\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/validation --recursive\n",
    "\n",
    "# Upload the rec files to the train and validation channels\n",
    "!aws s3 cp /tmp/{dataset_name}_train.rec $s3train_path\n",
    "!aws s3 cp /tmp/{dataset_name}_test.rec $s3validation_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the data for our model training to use\n",
    "Finally, we tell SageMaker where to find these RecordIO files to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(\n",
    "    s3train_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(\n",
    "    s3validation_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now it's time to train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an image classifier object with some base configuration\n",
    "More info here: https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, dataset_name)\n",
    "\n",
    "image_classifier = sagemaker.estimator.Estimator(training_image,role, train_instance_count=1, train_instance_type='ml.p3.2xlarge', output_path=s3_output_location, sagemaker_session=sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set some training hyperparameters\n",
    "\n",
    "Finally, before we train, we provide some additional configuration parameters for the training.\n",
    "\n",
    "More info here: https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=! ls -l {base_dir}/{dataset_name} | wc -l\n",
    "num_classes=int(num_classes[0]) - 1\n",
    "\n",
    "logger.info(\"number of classes is: \"+str(num_classes))\n",
    "\n",
    "num_training_samples=! cat {base_dir}/{dataset_name}_train.lst | wc -l\n",
    "num_training_samples = int(num_training_samples[0])\n",
    "\n",
    "logger.info(\"number of training samples is: \"+str(num_training_samples))\n",
    "\n",
    "# Learn more about the Sagemaker built-in Image Classifier hyperparameters here: https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html\n",
    "\n",
    "# These hyperparameters we won't want to change, as they define things like\n",
    "# the size of the images we'll be sending for input, the number of training classes we have, etc.\n",
    "base_hyperparameters=dict(\n",
    "    use_pretrained_model=1,\n",
    "    num_layers=34,\n",
    "    image_shape='3,215,215',\n",
    "    resize=430,\n",
    "    epochs=440,\n",
    "    augmentation_type='crop',\n",
    "    optimizer='sgd',\n",
    "    num_classes=num_classes,\n",
    "    num_training_samples=num_training_samples,\n",
    ")\n",
    "\n",
    "#logger.info(\"base parameters are: \"+base_hyperparameters)\n",
    "\n",
    "# These are hyperparameters we may want to tune, as they can affect the model training success:\n",
    "hyperparameters={\n",
    "    **base_hyperparameters, \n",
    "    **dict(\n",
    "        learning_rate=0.001,\n",
    "        mini_batch_size=5,\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "image_classifier.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "#logger.info(\"hyperparameters params are: \"+hyperparameters)\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the training\n",
    "Train our model!\n",
    "\n",
    "This will take some time because it's provisioning a new container runtime to train our model, then the actual training happens, then the trained model gets uploaded to S3 and the container is shut down.\n",
    "\n",
    "More info here: https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    **base_hyperparameters, \n",
    "    **dict(\n",
    "        learning_rate=0.0001,\n",
    "        mini_batch_size=5,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the base estimator, create a new one for incremental training\n",
    "incr_ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                        role,\n",
    "                                        instance_count=1,\n",
    "                                        instance_type='ml.p3.2xlarge',\n",
    "                                        volume_size=50,\n",
    "                                        max_run=360000,\n",
    "                                        input_mode='File',\n",
    "                                        output_path=s3_output_location,\n",
    "                                        sagemaker_session=sess,\n",
    "                                        hyperparameters=hyperparameters,\n",
    "                                        model_uri=\"s3://sagemaker-us-east-1-814180570813/dev/output/IC-dev-1673238974/output/model.tar.gz\") # This parameter will ingest the previous job's model as a new channel\n",
    "\n",
    "\n",
    "incr_ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install s3-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = 'sagemakertestwat'\n",
    "bucketdev = 'sagemakertestwat-dev'\n",
    "src_dataset_name = 'INC_DATA'\n",
    "dst_dataset_name = 'data'\n",
    "\n",
    "s3srcpath = 's3://{}/{}/'.format(bucket, src_dataset_name)\n",
    "s3dstpath = 's3://{}/{}/'.format(bucket, dst_dataset_name)\n",
    "\n",
    "# Copy 200 shoes from INC_DATA to data\n",
    "!aws s3 mv $s3srcpath $s3dstpath --recursive\n",
    "\n",
    "# Clean up INC_DATA\n",
    "#!aws s3 rm $s3srcpath --recursive\n",
    "\n",
    "AWS_ACCESS_KEY_ID = 'AKIA33EHRS264WAZWMFW'\n",
    "AWS_SECRET_ACCESS_KEY = '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'\n",
    "\n",
    "#c = boto.connect_s3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "#src = c.get_bucket('sagemakertestwat-dev')\n",
    "#dst = c.get_bucket('sagemakertestwat')\n",
    "\n",
    "#s3srcfile = 's3://{}/{}/{}'.format(bucket, src_dataset_name,)\n",
    "#s3dstpath = 's3://{}/{}/{}'.format(bucket, dst_dataset_name)\n",
    "\n",
    "\n",
    "dst_dataset_name = src_dataset_name\n",
    "\n",
    "count = 0\n",
    "\n",
    "'''\n",
    "for k in src.list():\n",
    "    for key in dst.list(prefix=\"data/\", delimiter=\"/\"):\n",
    "        if k.key == key:\n",
    "            continue\n",
    "    # copy stuff to your destination here\n",
    "    s3srcfile = 's3://{}/{}'.format(bucketdev, k.key)\n",
    "    s3dstpath = 's3://{}/{}'.format(bucket,dst_dataset_name)\n",
    "    \n",
    "    print(\"srcfile is \"+s3srcfile)\n",
    "    print(\"dstpath is \"+s3dstpath)\n",
    "    \n",
    "    !aws s3 cp $s3srcfile $s3dstpath\n",
    "    \n",
    "    count += 1\n",
    "    if count == 200:\n",
    "        break\n",
    "        \n",
    "'''\n",
    "\n",
    "#def list_folders(s3_client, bucket_name):  \n",
    "count = 0\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_objects_v2(Bucket=bucketdev, Prefix='', Delimiter='/') \n",
    "\n",
    "foldersToAdd = []\n",
    "\n",
    "# loop through folders in sagemakertestwat-dev\n",
    "for content in response.get('CommonPrefixes', []):  \n",
    "    folder = content.get('Prefix')\n",
    "    print(folder)\n",
    "    \n",
    "    incdataresponse = s3_client.list_objects_v2(Bucket=bucket, Prefix='data/', Delimiter='/') \n",
    "    #print(incdataresponse)\n",
    "    \n",
    "    folderMatch = False\n",
    "    \n",
    "    #loop through folders in data folder of sagemakertestwat\n",
    "    '''\n",
    "    for contentTwo in incdataresponse.get('CommonPrefixes', []): \n",
    "        folderTwo = contentTwo.get('Prefix')\n",
    "        #print(\"folderTwo is \" + folderTwo)\n",
    "        if folder in folderTwo: \n",
    "            print(\"match found\")\n",
    "            folderMatch = True\n",
    "            break\n",
    "    '''\n",
    "    \n",
    "    #if folderMatch == False:\n",
    "        \n",
    "    #s3srcfolder = 's3://{}/{}'.format(bucketdev, folder)\n",
    "    #s3dstpath = 's3://{}/{}/{}'.format(bucket,dst_dataset_name, folder)\n",
    "    # s3://sagemakertestwat/INC_DATA/\n",
    "        \n",
    "        #copy_source = {'Bucket': bucketdev,'Key': folder}\n",
    "        #s3.meta.client.copy(copy_source, bucket, dst_dataset_name)\n",
    "            \n",
    "    for contentTwo in incdataresponse.get('CommonPrefixes', []): \n",
    "        folderTwo = contentTwo.get('Prefix')\n",
    "        #print(\"folderTwo is \" + folderTwo)\n",
    "        if folder in folderTwo:\n",
    "            print(\"match found \"+folder)\n",
    "            folderMatch = True\n",
    "                \n",
    "    if folderMatch == False and count < 200:\n",
    "        foldersToAdd.append(folder)\n",
    "        print(\"adding: \"+folder)\n",
    "        count += 1\n",
    "        print(count)\n",
    "        \n",
    "    if count >= 200:\n",
    "        break\n",
    "\n",
    "for fldr in foldersToAdd:\n",
    "    \n",
    "    s3srcfolder = 's3://{}/{}'.format(bucketdev, fldr)\n",
    "    \n",
    "    newfldr = fldr.replace(\" \",\"_\")\n",
    "    newfldr = newfldr.replace(\"(\", \"\")\n",
    "    newfldr = newfldr.replace(\")\", \"\")\n",
    "    \n",
    "    s3newsrcfolder = 's3://{}/{}'.format(bucketdev, newfldr)\n",
    "    \n",
    "    !aws s3 mv \"$s3srcfolder\" \"$s3newsrcfolder\" --recursive\n",
    "    \n",
    "    s3dstpath = 's3://{}/{}/{}'.format(bucket,dst_dataset_name, newfldr)\n",
    "    \n",
    "    print(s3newsrcfolder)\n",
    "    print(s3dstpath)\n",
    "    \n",
    "    !aws s3 sync $s3newsrcfolder $s3dstpath    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "Once a model has been trained, we can use the same `image_classifier` object to create a deployed, fully-managed endpoint.}\n",
    "\n",
    "More info here: https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Deploying a model to an endpoint takes a few minutes to complete\n",
    "\n",
    "deployed_endpoint = image_classifier.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling a deployed endpoint from Python code\n",
    "\n",
    "If you want to try using a deployed endpoint from Python, here's a function that you can use. It takes in a path to the image you'd like to classify, and a list of all the classes used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def classify_deployed(file_name, classes):\n",
    "    payload = None\n",
    "    with open(file_name, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "\n",
    "    deployed_endpoint.content_type = 'application/x-image'\n",
    "    result = json.loads(deployed_endpoint.predict(payload))\n",
    "    best_prob_index = np.argmax(result)\n",
    "    return (classes[best_prob_index], result[best_prob_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Perform Hyperparameter Tuning\n",
    "\n",
    "Often, you might not know which values for hyperparameters like `learning_rate` and `mini_batch_size` will yield acceptible results. Traditionally, this meant manually running many training jobs with different hyperparameter values, looking at each trained model's performance, and then picking a winner. \n",
    "\n",
    "This type of manual tuning is _very_ time consuming, so you can automate this process using automatic model tuning with SageMaker. Here's some example code to illustrate how to start one of these jobs using the SageMaker Python SDK.\n",
    "\n",
    "More info here about automatic model tuning: https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html\n",
    "\n",
    "More info about model tuning for the Image Classification algorithm: https://docs.aws.amazon.com/sagemaker/latest/dg/IC-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'adam']),\n",
    "                         'learning_rate': ContinuousParameter(0.0001, 0.1),\n",
    "                         'mini_batch_size': IntegerParameter(2, 32),\n",
    "                        }\n",
    "\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "\n",
    "tuner = HyperparameterTuner(image_classifier,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=50,\n",
    "                            max_parallel_jobs=3)\n",
    "\n",
    "tuner.fit(inputs=data_channels, logs=True, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great resources to continue your Deep Learning journey\n",
    "\n",
    "[3Blue1Brown’s YouTube series on Neural Networks ~ 60 Minutes](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "\n",
    "[Fast.ai’s Practical Deep Learning for Coders ~ 14 Hours](http://www.fast.ai/)\n",
    "    \n",
    "[Amazon's Machine Learning University ~ More than 45 hours of courses, videos, and labs](https://aws.amazon.com/training/learning-paths/machine-learning/)\n",
    "    \n",
    "[Neural Networks and Deep Learning, by Michael Neilsen ~ 6 Chapter Book](http://neuralnetworksanddeeplearning.com/)\n",
    "\n",
    "[Amazon SageMaker - Fully-managed Platform](https://aws.amazon.com/sagemaker/)\n",
    "    \n",
    "[@gabehollombe's](https://twitter.com/gabehollombe) deep learning tools and demos\n",
    "- [Jupyter Notebooks](https://github.com/gabehollombe-aws/jupyter-notebooks)\n",
    "- [Webcam S3 Uploader Tool](https://github.com/gabehollombe-aws/webcam-s3-uploader)\n",
    "- [SageMaker Inference Web Tool](https://github.com/gabehollombe-aws/webcam-sagemaker-inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
